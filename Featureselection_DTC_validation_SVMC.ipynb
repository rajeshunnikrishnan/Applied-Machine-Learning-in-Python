{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is aimed at introducing concepts of Classification, Algorithms and Feature Selection \n",
    "\n",
    "UCI Mushroom Data Set available in http://archive.ics.uci.edu/ml/datasets/Mushroom?ref=datanews.io and is used for classifying mushrooms as poisonous or edible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mush_df = pd.read_csv('https://raw.githubusercontent.com/rajeshunnikrishnan/Applied-Machine-Learning-in-Python/master/mushrooms.csv')\n",
    "\n",
    "#Convert categorical variable in to dummy/indicator variable. mush_df has 23 columns and get_dummies create a dataframw with 119 columns. \n",
    "#For every column in the original dataframe, get_dummies create  columns for every unique value for that column. Each value is \n",
    "#then quanitifed using 1 or 0\n",
    "mush_df2 = pd.get_dummies(mush_df)\n",
    "\n",
    "X_mush = mush_df2.iloc[:,2:]\n",
    "y_mush = mush_df2.iloc[:,1]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_mush, y_mush, random_state=0)\n",
    "# For performance reasons in Questions 6 and 7, we will create a smaller version of the\n",
    "# entire mushroom dataset for use in those questions.  For simplicity we'll just re-use\n",
    "# the 25% test split created above as the representative subset.\n",
    "# Use the variables X_subset, y_subset for Questions 6 and 7.\n",
    "X_subset = X_test2\n",
    "y_subset = y_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify top 5 features in the dataset using Decision Tree Classifier.DecisionTreeClassifier is a class capable of doing multiclass classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['odor_n',\n",
       " 'stalk_root_c',\n",
       " 'stalk_root_r',\n",
       " 'spore_print_color_r',\n",
       " 'spore_print_color_u']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_importance():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    lst=[]\n",
    "       \n",
    "    clf = DecisionTreeClassifier().fit(X_train2, y_train2)\n",
    "    for i in (clf.feature_importances_.argsort()[::-1][:5]):\n",
    "        lst.append(X_train2.columns[i])\n",
    "    return (lst)\n",
    "\n",
    "feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine training and test scores for a Support Vector Classifier (SVC) with radial basis kernel. validation_curve class uses multipel combination of train and test data splits and computes the scores. In this example, 6 values of gamma from 0.0001 to 10 (i.e. np.logspace(-4,1,6)) is used to explore the impact. \n",
    "\n",
    "For each level of gamma, validation_curve will fit 3 models on different subsets of the data, returning two 6x3 (6 levels of gamma x 3 fits per level) arrays of the scores for the training and test sets.\n",
    "\n",
    "Return mean score across the three models for each level of gamma for both arrays, creating two arrays of length 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Scores: \n",
      " [[ 0.58906135  0.55686854  0.55350554]\n",
      " [ 0.93200296  0.9254062   0.93726937]\n",
      " [ 0.99039172  0.99039882  0.9904059 ]\n",
      " [ 1.          1.          1.        ]\n",
      " [ 1.          1.          1.        ]\n",
      " [ 1.          1.          1.        ]] \n",
      "\n",
      "Test Scores: \n",
      " [[ 0.58554572  0.56277696  0.55473373]\n",
      " [ 0.91445428  0.95125554  0.92307692]\n",
      " [ 0.98967552  0.99113737  0.98816568]\n",
      " [ 1.          1.          1.        ]\n",
      " [ 0.98967552  0.9985229   0.99704142]\n",
      " [ 0.52212389  0.52289513  0.52218935]] \n",
      "\n",
      "Average Train score for each gamma: \n",
      " [ 0.56647847  0.93155951  0.99039881  1.          1.          1.        ] \n",
      "\n",
      "Average Test score for each gamma: \n",
      " [ 0.56768547  0.92959558  0.98965952  1.          0.99507994  0.52240279]\n"
     ]
    }
   ],
   "source": [
    "def answer_six():\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import validation_curve\n",
    "    \n",
    "    clf=SVC(C=1,kernel='rbf',random_state=None)\n",
    "    param_range=np.logspace(-4,1,6)\n",
    "    \n",
    "    train_scores, test_scores=validation_curve(clf, X_subset, y_subset,\n",
    "                                            param_name='gamma',\n",
    "                                            param_range=param_range, cv=3, scoring='accuracy')\n",
    "    print('Train Scores:','\\n', train_scores,'\\n')\n",
    "    print('Test Scores:', '\\n',test_scores,'\\n')\n",
    "    print ('Average Train score for each gamma:','\\n',np.mean(train_scores,axis=1),'\\n')\n",
    "    print ('Average Test score for each gamma:','\\n',np.mean(test_scores,axis=1))\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
